#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from text_separator import TextSeparator

def test_sentence_separation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–±–∏–≤–∫—É —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    test_text = """
    –≠—Ç–æ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. –≠—Ç–æ –≤—Ç–æ—Ä–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ! –ê —ç—Ç–æ —Ç—Ä–µ—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ?
    –ß–µ—Ç–≤–µ—Ä—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ç–æ–∂–µ –≤–∞–∂–Ω–æ. –ü—è—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É.
    –®–µ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É. –°–µ–¥—å–º–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –º—ã—Å–ª—å.
    –í–æ—Å—å–º–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–∑–≤–∏–≤–∞–µ—Ç —Ç–µ–º—É. –î–µ–≤—è—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª–∏.
    –î–µ—Å—è—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç –≤—Ç–æ—Ä—É—é –≥—Ä—É–ø–ø—É.
    """
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–±–∏–≤–∫—É —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    print("=" * 60)
    print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{test_text}")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º TextSeparator
    separator = TextSeparator(test_text, mode='by_sense')
    sentences = separator.get_sentences()
    
    print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:")
    for i, sentence in enumerate(sentences, 1):
        print(f"{i:02d}: {sentence}")
    
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –ø–æ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    sentences_per_chunk = 5
    chunks = []
    
    for i in range(0, len(sentences), sentences_per_chunk):
        chunk_sentences = sentences[i:i + sentences_per_chunk]
        chunk_text = ' '.join(chunk_sentences)
        chunks.append({
            'sentences': chunk_sentences,
            'text': chunk_text,
            'length': len(chunk_text)
        })
    
    print(f"üìö –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –ø–æ {sentences_per_chunk} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:")
    for i, chunk in enumerate(chunks, 1):
        print(f"\nüìÑ –ß–ê–ù–ö #{i}")
        print(f"üìä –î–ª–∏–Ω–∞: {chunk['length']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(chunk['sentences'])}")
        print(f"üìñ –¢–µ–∫—Å—Ç: {chunk['text']}")
        print("-" * 40)

def test_epub_reading():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —á—Ç–µ–Ω–∏–µ EPUB —Ñ–∞–π–ª–∞"""
    epub_path = "/Users/matvey/Documents/books/Martyinenko_S._Bayiki_Dlya_Orujenosca.epub"
    
    if not os.path.exists(epub_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {epub_path}")
        return
    
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —á—Ç–µ–Ω–∏–µ EPUB —Ñ–∞–π–ª–∞")
    print("=" * 60)
    
    try:
        import warnings
        from bs4 import BeautifulSoup as bs, XMLParsedAsHTMLWarning
        import ebooklib
        from ebooklib import epub
        
        warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º EPUB
        book = epub.read_epub(epub_path)
        print(f"üìö –ö–Ω–∏–≥–∞: {book.title}")
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã
        item_ids = []
        doc_item_list = book.get_items_of_type(ebooklib.ITEM_DOCUMENT)
        for elem in doc_item_list:
            item_ids.append(elem.id)
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(item_ids)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —ç–ª–µ–º–µ–Ω—Ç–∞
        for i, item_id in enumerate(item_ids[:3]):
            print(f"\nüìñ –≠–ª–µ–º–µ–Ω—Ç {i+1}: {item_id}")
            
            try:
                item_doc = book.get_item_with_id(item_id)
                if item_doc is None:
                    print(f"‚ö†Ô∏è –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    continue
                
                soup = bs(item_doc.content.decode('utf-8'), "xml")
                if soup.body:
                    text = soup.body.get_text()
                else:
                    text = soup.get_text()
                
                text = ' '.join(text.split())
                
                if text.strip():
                    print(f"üìÑ –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"üìù –ü—Ä–µ–≤—å—é: {text[:200]}...")
                    
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    separator = TextSeparator(text, mode='by_sense')
                    sentences = separator.get_sentences()
                    print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                    for j, sentence in enumerate(sentences[:5], 1):
                        print(f"  {j}: {sentence[:100]}{'...' if len(sentence) > 100 else ''}")
                    
                    if len(sentences) > 5:
                        print(f"  ... –∏ –µ—â–µ {len(sentences) - 5} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                else:
                    print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ EPUB: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º")
    print("=" * 60)
    
    # –¢–µ—Å—Ç 1: –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    test_sentence_separation()
    
    # –¢–µ—Å—Ç 2: –ß—Ç–µ–Ω–∏–µ EPUB
    test_epub_reading()
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()
